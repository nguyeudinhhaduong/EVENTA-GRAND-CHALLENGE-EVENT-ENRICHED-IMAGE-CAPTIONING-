{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875baf35",
   "metadata": {
    "papermill": {
     "duration": 0.003241,
     "end_time": "2025-06-10T13:55:13.780632",
     "exception": false,
     "start_time": "2025-06-10T13:55:13.777391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Setting and Preparing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df0502c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:55:13.786775Z",
     "iopub.status.busy": "2025-06-10T13:55:13.786448Z",
     "iopub.status.idle": "2025-06-10T13:55:16.880609Z",
     "shell.execute_reply": "2025-06-10T13:55:16.879676Z"
    },
    "papermill": {
     "duration": 3.09877,
     "end_time": "2025-06-10T13:55:16.882137",
     "exception": false,
     "start_time": "2025-06-10T13:55:13.783367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'FlagEmbedding'...\r\n",
      "remote: Enumerating objects: 11099, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (192/192), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (113/113), done.\u001b[K\r\n",
      "remote: Total 11099 (delta 115), reused 98 (delta 79), pack-reused 10907 (from 2)\u001b[K\r\n",
      "Receiving objects: 100% (11099/11099), 51.14 MiB | 30.78 MiB/s, done.\r\n",
      "Resolving deltas: 100% (6046/6046), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/FlagOpen/FlagEmbedding.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d1cf5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:55:16.892215Z",
     "iopub.status.busy": "2025-06-10T13:55:16.891569Z",
     "iopub.status.idle": "2025-06-10T13:58:27.131398Z",
     "shell.execute_reply": "2025-06-10T13:58:27.130535Z"
    },
    "papermill": {
     "duration": 190.246392,
     "end_time": "2025-06-10T13:58:27.133010",
     "exception": false,
     "start_time": "2025-06-10T13:55:16.886618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/FlagEmbedding\n",
      "Processing /kaggle/working/FlagEmbedding\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding==1.3.5) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: transformers>=4.44.2 in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding==1.3.5) (4.51.3)\r\n",
      "Requirement already satisfied: datasets>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding==1.3.5) (3.6.0)\r\n",
      "Requirement already satisfied: accelerate>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding==1.3.5) (1.5.2)\r\n",
      "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding==1.3.5) (3.4.1)\r\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding==1.3.5) (0.14.0)\r\n",
      "Collecting ir-datasets (from FlagEmbedding==1.3.5)\r\n",
      "  Downloading ir_datasets-0.5.10-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding==1.3.5) (0.2.0)\r\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding==1.3.5) (3.20.3)\r\n",
      "Collecting deepspeed (from FlagEmbedding==1.3.5)\r\n",
      "  Downloading deepspeed-0.17.1.tar.gz (1.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting flash-attn (from FlagEmbedding==1.3.5)\r\n",
      "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->FlagEmbedding==1.3.5) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->FlagEmbedding==1.3.5) (25.0)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->FlagEmbedding==1.3.5) (7.0.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->FlagEmbedding==1.3.5) (6.0.2)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->FlagEmbedding==1.3.5) (0.31.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->FlagEmbedding==1.3.5) (0.5.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding==1.3.5) (3.18.0)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding==1.3.5) (19.0.1)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding==1.3.5) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding==1.3.5) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding==1.3.5) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding==1.3.5) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding==1.3.5) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->FlagEmbedding==1.3.5) (0.70.16)\r\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding==1.3.5)\r\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding==1.3.5) (4.13.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding==1.3.5) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding==1.3.5) (3.1.6)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding==1.3.5) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding==1.3.5) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding==1.3.5) (12.4.127)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6.0->FlagEmbedding==1.3.5)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6.0->FlagEmbedding==1.3.5)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6.0->FlagEmbedding==1.3.5)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6.0->FlagEmbedding==1.3.5)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6.0->FlagEmbedding==1.3.5)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6.0->FlagEmbedding==1.3.5)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding==1.3.5) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding==1.3.5) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding==1.3.5) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6.0->FlagEmbedding==1.3.5)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding==1.3.5) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->FlagEmbedding==1.3.5) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->FlagEmbedding==1.3.5) (1.3.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.44.2->FlagEmbedding==1.3.5) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.44.2->FlagEmbedding==1.3.5) (0.21.1)\r\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepspeed->FlagEmbedding==1.3.5) (0.8.1)\r\n",
      "Collecting hjson (from deepspeed->FlagEmbedding==1.3.5)\r\n",
      "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed->FlagEmbedding==1.3.5) (1.1.0)\r\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from deepspeed->FlagEmbedding==1.3.5) (1.11.1.4)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed->FlagEmbedding==1.3.5) (9.0.0)\r\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed->FlagEmbedding==1.3.5) (2.11.4)\r\n",
      "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from deepspeed->FlagEmbedding==1.3.5) (12.575.51)\r\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->FlagEmbedding==1.3.5) (4.13.3)\r\n",
      "Collecting inscriptis>=2.2.0 (from ir-datasets->FlagEmbedding==1.3.5)\r\n",
      "  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\r\n",
      "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->FlagEmbedding==1.3.5) (5.3.1)\r\n",
      "Collecting trec-car-tools>=2.5.4 (from ir-datasets->FlagEmbedding==1.3.5)\r\n",
      "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\r\n",
      "Collecting lz4>=3.1.10 (from ir-datasets->FlagEmbedding==1.3.5)\r\n",
      "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\n",
      "Collecting warc3-wet>=0.2.3 (from ir-datasets->FlagEmbedding==1.3.5)\r\n",
      "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->FlagEmbedding==1.3.5)\r\n",
      "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting zlib-state>=0.1.3 (from ir-datasets->FlagEmbedding==1.3.5)\r\n",
      "  Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\r\n",
      "Collecting ijson>=3.1.3 (from ir-datasets->FlagEmbedding==1.3.5)\r\n",
      "  Downloading ijson-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\r\n",
      "Collecting unlzw3>=0.2.1 (from ir-datasets->FlagEmbedding==1.3.5)\r\n",
      "  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers->FlagEmbedding==1.3.5) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers->FlagEmbedding==1.3.5) (1.15.2)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers->FlagEmbedding==1.3.5) (11.1.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->FlagEmbedding==1.3.5) (2.6)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding==1.3.5) (3.11.18)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.20.1->FlagEmbedding==1.3.5) (1.1.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding==1.3.5) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding==1.3.5) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding==1.3.5) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding==1.3.5) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding==1.3.5) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding==1.3.5) (2.4.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed->FlagEmbedding==1.3.5) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed->FlagEmbedding==1.3.5) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed->FlagEmbedding==1.3.5) (0.4.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding==1.3.5) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding==1.3.5) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding==1.3.5) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding==1.3.5) (2025.4.26)\r\n",
      "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->FlagEmbedding==1.3.5)\r\n",
      "  Downloading cbor-1.0.0.tar.gz (20 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->FlagEmbedding==1.3.5) (3.0.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.19.0->FlagEmbedding==1.3.5) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.19.0->FlagEmbedding==1.3.5) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.19.0->FlagEmbedding==1.3.5) (2025.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding==1.3.5) (1.5.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding==1.3.5) (3.6.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding==1.3.5) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding==1.3.5) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding==1.3.5) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding==1.3.5) (1.6.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding==1.3.5) (6.4.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding==1.3.5) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding==1.3.5) (1.20.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.19.0->FlagEmbedding==1.3.5) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding==1.3.5) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding==1.3.5) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding==1.3.5) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding==1.3.5) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding==1.3.5) (2024.2.0)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ir_datasets-0.5.10-py3-none-any.whl (859 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ijson-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.0/135.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\r\n",
      "Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\r\n",
      "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\r\n",
      "Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\r\n",
      "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: FlagEmbedding, deepspeed, flash-attn, warc3-wet-clueweb09, cbor\r\n",
      "  Building wheel for FlagEmbedding (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for FlagEmbedding: filename=FlagEmbedding-1.3.5-py3-none-any.whl size=331826 sha256=7e338e647a5dd61180c5900d7d6755c5f7518080828af05c7f8c91b58497abcf\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-gf_geia9/wheels/e5/f1/8f/667ddc375b197e25f38f0a68a2f77fb89a55202afebdeedb82\r\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for deepspeed: filename=deepspeed-0.17.1-py3-none-any.whl size=1690728 sha256=3bc23e8b9263014d7f6c19964a409ddcc54002d2f31c7b3a11953e3ba20b9293\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/34/86/36/22db26525829160fd1c4add33d8a834ec046b90abf45cd363b\r\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187831595 sha256=58853b28a5a926cae14402bfd8d4d93a45ebf8f9e79533f37ab09d0d77a99c05\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\r\n",
      "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=fef7621c14f828b1222cfe1a62f5248d9a98d9e1784a41af15b7d18efed3cfa7\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/63/f9/dc/2dd16d3330e327236e4d407941975c42d5159d200cdb7922d8\r\n",
      "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for cbor: filename=cbor-1.0.0-cp311-cp311-linux_x86_64.whl size=53928 sha256=094626ec73f37980d9e18f0830498c5b6a606591c9b829a43d07ddf9d16806b9\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/6b/45/0c34253b1af07d1d9dc524f6d44d74a6b191c43152e6aaf641\r\n",
      "Successfully built FlagEmbedding deepspeed flash-attn warc3-wet-clueweb09 cbor\r\n",
      "Installing collected packages: warc3-wet-clueweb09, warc3-wet, hjson, cbor, zlib-state, unlzw3, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, lz4, ijson, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, inscriptis, nvidia-cusolver-cu12, flash-attn, trec-car-tools, ir-datasets, FlagEmbedding, deepspeed\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2025.3.2\r\n",
      "    Uninstalling fsspec-2025.3.2:\r\n",
      "      Successfully uninstalled fsspec-2025.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed FlagEmbedding-1.3.5 cbor-1.0.0 deepspeed-0.17.1 flash-attn-2.7.4.post1 fsspec-2025.3.0 hjson-3.1.0 ijson-3.4.0 inscriptis-2.6.0 ir-datasets-0.5.10 lz4-4.4.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.9\r\n",
      "Collecting deepspeed==0.15.4\r\n",
      "  Downloading deepspeed-0.15.4.tar.gz (1.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: hjson in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4) (3.1.0)\r\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4) (1.1.0)\r\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4) (1.11.1.4)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4) (25.0)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4) (7.0.0)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4) (9.0.0)\r\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4) (2.11.4)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4) (4.67.1)\r\n",
      "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4) (12.575.51)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed==0.15.4) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed==0.15.4) (2.33.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed==0.15.4) (4.13.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed==0.15.4) (0.4.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->deepspeed==0.15.4) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->deepspeed==0.15.4) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->deepspeed==0.15.4) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->deepspeed==0.15.4) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->deepspeed==0.15.4) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->deepspeed==0.15.4) (2.4.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (3.18.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (2025.3.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed==0.15.4) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->deepspeed==0.15.4) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->deepspeed==0.15.4) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->deepspeed==0.15.4) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->deepspeed==0.15.4) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->deepspeed==0.15.4) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->deepspeed==0.15.4) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->deepspeed==0.15.4) (2024.2.0)\r\n",
      "Building wheels for collected packages: deepspeed\r\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for deepspeed: filename=deepspeed-0.15.4-py3-none-any.whl size=1527838 sha256=0a89c7ad2415f20381e55b9fe0c4fbce7238c155da10db2c5ff6d07bb7413a0e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/b7/07/035dfeaae31b5766822083a749891e45aab9c72d25a78b7dd0\r\n",
      "Successfully built deepspeed\r\n",
      "Installing collected packages: deepspeed\r\n",
      "  Attempting uninstall: deepspeed\r\n",
      "    Found existing installation: deepspeed 0.17.1\r\n",
      "    Uninstalling deepspeed-0.17.1:\r\n",
      "      Successfully uninstalled deepspeed-0.17.1\r\n",
      "Successfully installed deepspeed-0.15.4\r\n"
     ]
    }
   ],
   "source": [
    "%cd FlagEmbedding\n",
    "!pip install .[finetune]\n",
    "!pip install deepspeed==0.15.4 \n",
    "# Notebook gốc ghi deepspeed==0.15.4, hãy đảm bảo bạn dùng phiên bản tương thích\n",
    "# hoặc nếu có lỗi, thử với phiên bản mà FlagEmbedding khuyến nghị tại thời điểm bạn chạy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3f5904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:58:27.192837Z",
     "iopub.status.busy": "2025-06-10T13:58:27.192541Z",
     "iopub.status.idle": "2025-06-10T13:58:30.606682Z",
     "shell.execute_reply": "2025-06-10T13:58:30.605831Z"
    },
    "papermill": {
     "duration": 3.445612,
     "end_time": "2025-06-10T13:58:30.608220",
     "exception": false,
     "start_time": "2025-06-10T13:58:27.162608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7610b410",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:58:30.669208Z",
     "iopub.status.busy": "2025-06-10T13:58:30.668954Z",
     "iopub.status.idle": "2025-06-10T13:58:32.445730Z",
     "shell.execute_reply": "2025-06-10T13:58:32.444909Z"
    },
    "papermill": {
     "duration": 1.808594,
     "end_time": "2025-06-10T13:58:32.447163",
     "exception": false,
     "start_time": "2025-06-10T13:58:30.638569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ccc818e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:58:32.513458Z",
     "iopub.status.busy": "2025-06-10T13:58:32.512794Z",
     "iopub.status.idle": "2025-06-10T13:58:32.598997Z",
     "shell.execute_reply": "2025-06-10T13:58:32.598158Z"
    },
    "papermill": {
     "duration": 0.119672,
     "end_time": "2025-06-10T13:58:32.600265",
     "exception": false,
     "start_time": "2025-06-10T13:58:32.480593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: Tesla T4\n",
      "Number of GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"GPU is NOT available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb68cef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:58:32.712032Z",
     "iopub.status.busy": "2025-06-10T13:58:32.711762Z",
     "iopub.status.idle": "2025-06-10T13:58:32.725606Z",
     "shell.execute_reply": "2025-06-10T13:58:32.725008Z"
    },
    "papermill": {
     "duration": 0.096251,
     "end_time": "2025-06-10T13:58:32.726716",
     "exception": false,
     "start_time": "2025-06-10T13:58:32.630465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_custom_data_to_flagembedding_jsonl(input_json_path, output_jsonl_path):\n",
    "    \"\"\"\n",
    "    Chuyển đổi dữ liệu JSON tùy chỉnh sang định dạng JSONL mà FlagEmbedding M3 finetuning mong đợi.\n",
    "\n",
    "    Args:\n",
    "        input_json_path (str): Đường dẫn đến file JSON đầu vào.\n",
    "                               Giả định file chứa một danh sách các đối tượng,\n",
    "                               mỗi đối tượng có \"query_caption\", \"positive_chunks\", và \"negative_chunks\".\n",
    "        output_jsonl_path (str): Đường dẫn để lưu file JSONL đầu ra.\n",
    "    \"\"\"\n",
    "    print(f\"Bắt đầu chuyển đổi file: {input_json_path}\")\n",
    "    items_processed_count = 0\n",
    "    items_skipped_count = 0\n",
    "    try:\n",
    "        with open(input_json_path, 'r', encoding='utf-8') as infile, \\\n",
    "             open(output_jsonl_path, 'w', encoding='utf-8') as outfile:\n",
    "\n",
    "            # Tải toàn bộ dữ liệu JSON.\n",
    "            # Giả định rằng file JSON đầu vào của bạn là một danh sách (JSON array)\n",
    "            # chứa các dictionary \"training_triplets_batch\" của bạn.\n",
    "            try:\n",
    "                custom_data_list = json.load(infile)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Lỗi: Không thể giải mã JSON từ file {input_json_path}. Lỗi: {e}\")\n",
    "                print(\"Hãy đảm bảo file là một JSON array hợp lệ, ví dụ: [{\\\"key\\\": \\\"value\\\"}, ...]\")\n",
    "                return\n",
    "\n",
    "            if not isinstance(custom_data_list, list):\n",
    "                # Nếu file JSON của bạn không phải là một list ở cấp độ gốc,\n",
    "                # ví dụ, nó là một dictionary chứa list dữ liệu trong một key cụ thể (ví dụ: {\"data\": [...]}),\n",
    "                # bạn cần điều chỉnh ở đây để truy cập vào list đó.\n",
    "                # Ví dụ: custom_data_list = custom_data_list.get(\"your_data_key\", [])\n",
    "                print(f\"Cảnh báo: Dữ liệu JSON đầu vào không phải là một danh sách (list). Nó là một {type(custom_data_list)}.\")\n",
    "                print(\"Script này giả định cấu trúc JSON là một danh sách các mục huấn luyện.\")\n",
    "                print(\"Nếu dữ liệu của bạn nằm trong một key của JSON object, vui lòng điều chỉnh script này hoặc tiền xử lý file JSON của bạn.\")\n",
    "                # Để thử xử lý trường hợp file chỉ chứa một object đơn lẻ (không phải list)\n",
    "                if isinstance(custom_data_list, dict) and \"query_caption\" in custom_data_list:\n",
    "                    print(\"Dường như file chứa một bản ghi đơn lẻ. Sẽ xử lý nó như một danh sách một mục.\")\n",
    "                    custom_data_list = [custom_data_list]\n",
    "                else:\n",
    "                    print(f\"Lỗi: Không thể xử lý định dạng JSON đầu vào. Kết thúc chuyển đổi.\")\n",
    "                    return\n",
    "\n",
    "\n",
    "            for item_index, item in enumerate(custom_data_list):\n",
    "                query_caption = item.get(\"query_caption\")\n",
    "                positive_chunks_data = item.get(\"positive_chunks\", []) # list {text, score}\n",
    "                negative_chunks_data = item.get(\"negative_chunks\", []) # list {text, score, article_id}\n",
    "\n",
    "                if not query_caption:\n",
    "                    print(f\"Cảnh báo: Bỏ qua mục {item_index} do thiếu 'query_caption': {item}\")\n",
    "                    items_skipped_count += 1\n",
    "                    continue\n",
    "\n",
    "                # Trích xuất văn bản từ positive_chunks.\n",
    "                # FlagEmbedding thường mong đợi một danh sách các positive passages.\n",
    "                # Ở đây, chúng ta sẽ lấy văn bản từ chunk đầu tiên trong \"positive_chunks\".\n",
    "                # Nếu bạn muốn sử dụng tất cả 5 chunks, bạn có thể đưa tất cả vào,\n",
    "                # script huấn luyện có thể chọn một trong số đó.\n",
    "                # positive_texts = []\n",
    "                # if positive_chunks_data:\n",
    "                #     # Lấy text của chunk đầu tiên làm positive chính\n",
    "                #     first_positive_chunk = positive_chunks_data[0]\n",
    "                #     if isinstance(first_positive_chunk, dict) and \"text\" in first_positive_chunk:\n",
    "                #         positive_texts.append(first_positive_chunk[\"text\"])\n",
    "                #     else:\n",
    "                #         print(f\"Cảnh báo: Bỏ qua mục {item_index} cho query '{query_caption[:50]}...' do positive_chunk đầu tiên không hợp lệ: {first_positive_chunk}\")\n",
    "                #         items_skipped_count += 1\n",
    "                #         continue\n",
    "                # else:\n",
    "                #     print(f\"Cảnh báo: Bỏ qua mục {item_index} cho query '{query_caption[:50]}...' do thiếu 'positive_chunks'.\")\n",
    "                #     items_skipped_count += 1\n",
    "                #     continue\n",
    "\n",
    "                # if not positive_texts: # Phòng trường hợp positive_texts rỗng dù đã qua kiểm tra\n",
    "                #     print(f\"Cảnh báo: Bỏ qua mục {item_index} cho query '{query_caption[:50]}...' do không trích xuất được positive text.\")\n",
    "                #     items_skipped_count += 1\n",
    "                #     continue\n",
    "\n",
    "                positive_texts = []\n",
    "                if positive_chunks_data:\n",
    "                    valid_pos_found = False\n",
    "                    for pos_chunk_idx, pos_chunk in enumerate(positive_chunks_data):\n",
    "                        if isinstance(pos_chunk, dict) and \"text\" in pos_chunk:\n",
    "                            positive_texts.append(pos_chunk[\"text\"])\n",
    "                            valid_pos_found = True\n",
    "                        else:\n",
    "                            print(f\"Cảnh báo: Positive_chunk không hợp lệ tại vị trí {pos_chunk_idx} cho query '{query_caption[:50]}...': {pos_chunk}. Sẽ bỏ qua chunk này.\")\n",
    "                    \n",
    "                    if not valid_pos_found: # Nếu lặp qua hết mà không có positive hợp lệ nào\n",
    "                        print(f\"Cảnh báo: Bỏ qua mục {item_index} cho query '{query_caption[:50]}...' do không có positive_chunk nào hợp lệ trong danh sách được cung cấp.\")\n",
    "                        items_skipped_count += 1\n",
    "                        continue\n",
    "                else:\n",
    "                    print(f\"Cảnh báo: Bỏ qua mục {item_index} cho query '{query_caption[:50]}...' do thiếu 'positive_chunks'.\")\n",
    "                    items_skipped_count += 1\n",
    "                    continue\n",
    "\n",
    "                # Trích xuất văn bản từ negative_chunks\n",
    "                negative_texts = []\n",
    "                for neg_chunk_index, neg_chunk in enumerate(negative_chunks_data):\n",
    "                    if isinstance(neg_chunk, dict) and \"text\" in neg_chunk:\n",
    "                        negative_texts.append(neg_chunk[\"text\"])\n",
    "                    else:\n",
    "                        print(f\"Cảnh báo: Negative_chunk không hợp lệ tại vị trí {neg_chunk_index} cho query '{query_caption[:50]}...': {neg_chunk}\")\n",
    "\n",
    "                # Script của FlagEmbedding thường cần cả positive và negative passages.\n",
    "                # Nếu không có negative_texts, script có thể dựa vào \"in-batch negatives\".\n",
    "                # Tuy nhiên, việc cung cấp negatives rõ ràng thường tốt hơn.\n",
    "                if not negative_texts:\n",
    "                    print(f\"Thông tin: Không tìm thấy negative_texts tường minh cho query: '{query_caption[:50]}...'. \"\n",
    "                          \"Script huấn luyện có thể sẽ sử dụng in-batch negatives.\")\n",
    "                    # Bạn có thể quyết định bỏ qua nếu không có negative tường minh,\n",
    "                    # tùy thuộc vào chiến lược fine-tuning và khả năng của script FlagEmbedding.\n",
    "                    # Với mục đích chuyển đổi, chúng ta sẽ cho phép danh sách negative_texts rỗng.\n",
    "\n",
    "                # Tạo đối tượng JSON cho dòng hiện tại trong file .jsonl\n",
    "                # Định dạng mong đợi: {\"query\": str, \"pos\": list[str], \"neg\": list[str]}\n",
    "                output_record = {\n",
    "                    \"query\": query_caption,\n",
    "                    \"pos\": positive_texts,  # Danh sách chứa văn bản của positive chunk (hoặc các chunks)\n",
    "                    \"neg\": negative_texts   # Danh sách các văn bản từ negative chunks\n",
    "                }\n",
    "                outfile.write(json.dumps(output_record, ensure_ascii=False) + \"\\n\")\n",
    "                items_processed_count += 1\n",
    "\n",
    "            print(f\"Hoàn tất chuyển đổi.\")\n",
    "            print(f\"Tổng số mục đã xử lý và ghi ra file: {items_processed_count}\")\n",
    "            print(f\"Tổng số mục bị bỏ qua: {items_skipped_count}\")\n",
    "            print(f\"File JSONL đã được lưu tại: {output_jsonl_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file đầu vào tại {input_json_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Đã xảy ra lỗi không mong muốn trong quá trình chuyển đổi: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b274ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:58:32.788710Z",
     "iopub.status.busy": "2025-06-10T13:58:32.788199Z",
     "iopub.status.idle": "2025-06-10T13:58:39.534258Z",
     "shell.execute_reply": "2025-06-10T13:58:39.533358Z"
    },
    "papermill": {
     "duration": 6.778073,
     "end_time": "2025-06-10T13:58:39.535454",
     "exception": false,
     "start_time": "2025-06-10T13:58:32.757381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chuẩn bị chuyển đổi dữ liệu từ: /kaggle/input/1-train-set-for-bge-m3-langchain-1000-2000-local/training_triplets_bm25_top_n_LangChain_1000_2000_local_pos.json\n",
      "Dữ liệu sau chuyển đổi sẽ được lưu tại: /kaggle/working/training_data_for_flagembedding.jsonl\n",
      "Bắt đầu chuyển đổi file: /kaggle/input/1-train-set-for-bge-m3-langchain-1000-2000-local/training_triplets_bm25_top_n_LangChain_1000_2000_local_pos.json\n",
      "Hoàn tất chuyển đổi.\n",
      "Tổng số mục đã xử lý và ghi ra file: 3229\n",
      "Tổng số mục bị bỏ qua: 0\n",
      "File JSONL đã được lưu tại: /kaggle/working/training_data_for_flagembedding.jsonl\n",
      "Quá trình chuẩn bị dữ liệu hoàn tất.\n"
     ]
    }
   ],
   "source": [
    "input_json_file = \"/kaggle/input/1-train-set-for-bge-m3-langchain-1000-2000-local/training_triplets_bm25_top_n_LangChain_1000_2000_local_pos.json\"\n",
    "prepared_training_jsonl_file = \"/kaggle/working/training_data_for_flagembedding.jsonl\"\n",
    "\n",
    "print(f\"Chuẩn bị chuyển đổi dữ liệu từ: {input_json_file}\")\n",
    "print(f\"Dữ liệu sau chuyển đổi sẽ được lưu tại: {prepared_training_jsonl_file}\")\n",
    "convert_custom_data_to_flagembedding_jsonl(input_json_file, prepared_training_jsonl_file)\n",
    "print(\"Quá trình chuẩn bị dữ liệu hoàn tất.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bd59bd",
   "metadata": {
    "papermill": {
     "duration": 0.031024,
     "end_time": "2025-06-10T13:58:39.597567",
     "exception": false,
     "start_time": "2025-06-10T13:58:39.566543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## II. Finetuned ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60add1e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:58:39.658049Z",
     "iopub.status.busy": "2025-06-10T13:58:39.657326Z",
     "iopub.status.idle": "2025-06-10T13:58:39.749882Z",
     "shell.execute_reply": "2025-06-10T13:58:39.749218Z"
    },
    "papermill": {
     "duration": 0.124346,
     "end_time": "2025-06-10T13:58:39.751343",
     "exception": false,
     "start_time": "2025-06-10T13:58:39.626997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "wandb_api_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "os.environ[\"WANDB_API_KEY\"] = wandb_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d46b198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:58:39.811532Z",
     "iopub.status.busy": "2025-06-10T13:58:39.811043Z",
     "iopub.status.idle": "2025-06-10T19:48:28.213519Z",
     "shell.execute_reply": "2025-06-10T19:48:28.212540Z"
    },
    "papermill": {
     "duration": 20988.433375,
     "end_time": "2025-06-10T19:48:28.215351",
     "exception": false,
     "start_time": "2025-06-10T13:58:39.781976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0610 13:58:41.720000 392 torch/distributed/run.py:792] \r\n",
      "W0610 13:58:41.720000 392 torch/distributed/run.py:792] *****************************************\r\n",
      "W0610 13:58:41.720000 392 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \r\n",
      "W0610 13:58:41.720000 392 torch/distributed/run.py:792] *****************************************\r\n",
      "2025-06-10 13:58:48.383922: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-06-10 13:58:48.383937: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1749563928.409074     395 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1749563928.409322     394 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1749563928.416767     394 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1749563928.416770     395 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "[2025-06-10 13:58:52,589] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\r\n",
      "[2025-06-10 13:58:52,599] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\r\n",
      "[2025-06-10 13:58:55,839] [INFO] [comm.py:652:init_distributed] cdb=None\r\n",
      "[2025-06-10 13:58:55,839] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\r\n",
      "[2025-06-10 13:58:55,843] [INFO] [comm.py:652:init_distributed] cdb=None\r\n",
      "tokenizer_config.json: 100%|███████████████████| 444/444 [00:00<00:00, 2.69MB/s]\r\n",
      "sentencepiece.bpe.model: 100%|█████████████| 5.07M/5.07M [00:00<00:00, 56.7MB/s]\r\n",
      "tokenizer.json: 100%|███████████████████████| 17.1M/17.1M [00:00<00:00, 153MB/s]\r\n",
      "special_tokens_map.json: 100%|█████████████████| 964/964 [00:00<00:00, 5.60MB/s]\r\n",
      "config.json: 100%|█████████████████████████████| 687/687 [00:00<00:00, 3.96MB/s]\r\n",
      "Fetching 30 files:   0%|                                 | 0/30 [00:00<?, ?it/s]\r\n",
      "README.md: 100%|███████████████████████████| 15.8k/15.8k [00:00<00:00, 33.7MB/s]\r\n",
      "\r\n",
      "config.json: 100%|█████████████████████████████| 191/191 [00:00<00:00, 1.65MB/s]\r\n",
      "\r\n",
      "config.json: 100%|█████████████████████████████| 687/687 [00:00<00:00, 5.24MB/s]\r\n",
      "\r\n",
      "config_sentence_transformers.json: 100%|████████| 123/123 [00:00<00:00, 938kB/s]\r\n",
      "\r\n",
      ".DS_Store: 100%|███████████████████████████| 6.15k/6.15k [00:00<00:00, 27.0MB/s]\r\n",
      "\r\n",
      ".gitattributes: 100%|██████████████████████| 1.63k/1.63k [00:00<00:00, 9.48MB/s]\r\n",
      "Fetching 30 files:   3%|▊                        | 1/30 [00:00<00:03,  8.32it/s]\r\n",
      "colbert_linear.pt:   0%|                            | 0.00/2.10M [00:00<?, ?B/s]\u001b[A\r\n",
      "\r\n",
      "long.jpg:   0%|                                      | 0.00/485k [00:00<?, ?B/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "mkqa.jpg:   0%|                                      | 0.00/608k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "miracl.jpg:   0%|                                    | 0.00/576k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "nqa.jpg:   0%|                                       | 0.00/158k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "others.webp: 100%|█████████████████████████| 21.0k/21.0k [00:00<00:00, 47.2MB/s]\r\n",
      "colbert_linear.pt: 100%|███████████████████| 2.10M/2.10M [00:00<00:00, 27.4MB/s]\r\n",
      "\r\n",
      "long.jpg: 100%|██████████████████████████████| 485k/485k [00:00<00:00, 12.1MB/s]\r\n",
      "nqa.jpg: 100%|███████████████████████████████| 158k/158k [00:00<00:00, 6.30MB/s]\r\n",
      "long.jpg: 100%|██████████████████████████████| 127k/127k [00:00<00:00, 7.38MB/s]\r\n",
      "mkqa.jpg: 100%|██████████████████████████████| 608k/608k [00:00<00:00, 12.3MB/s]\r\n",
      "miracl.jpg: 100%|████████████████████████████| 576k/576k [00:00<00:00, 10.2MB/s]\r\n",
      "\r\n",
      "modules.json: 100%|████████████████████████████| 349/349 [00:00<00:00, 4.23MB/s]\r\n",
      "\r\n",
      "Constant_7_attr__value:   0%|                       | 0.00/65.6k [00:00<?, ?B/s]\u001b[A\r\n",
      "\r\n",
      "config.json: 100%|█████████████████████████████| 698/698 [00:00<00:00, 5.57MB/s]\r\n",
      "Constant_7_attr__value: 100%|██████████████| 65.6k/65.6k [00:00<00:00, 6.35MB/s]\r\n",
      "\r\n",
      "model.onnx:   0%|                                    | 0.00/725k [00:00<?, ?B/s]\u001b[A\r\n",
      "\r\n",
      "Fetching 30 files:   0%|                                 | 0/30 [00:00<?, ?it/s]\r\n",
      "\r\n",
      "\r\n",
      "special_tokens_map.json: 100%|█████████████████| 964/964 [00:00<00:00, 6.34MB/s]\r\n",
      "model.onnx: 100%|████████████████████████████| 725k/725k [00:00<00:00, 14.6MB/s]\r\n",
      "\r\n",
      "pytorch_model.bin:   0%|                            | 0.00/2.27G [00:00<?, ?B/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "sentencepiece.bpe.model:   0%|                      | 0.00/5.07M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "tokenizer_config.json: 100%|███████████████| 1.17k/1.17k [00:00<00:00, 7.75MB/s]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "tokenizer.json:   0%|                               | 0.00/17.1M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "sentence_bert_config.json: 100%|██████████████| 54.0/54.0 [00:00<00:00, 235kB/s]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "bm25.jpg:   0%|                                      | 0.00/132k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:   0%|                     | 10.5M/2.27G [00:00<00:29, 76.7MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "sentencepiece.bpe.model: 100%|█████████████| 5.07M/5.07M [00:00<00:00, 39.8MB/s]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "sparse_linear.pt: 100%|████████████████████| 3.52k/3.52k [00:00<00:00, 20.1MB/s]\r\n",
      "\r\n",
      "pytorch_model.bin:   1%|▏                   | 21.0M/2.27G [00:00<00:18, 125MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:   1%|▏                    | 21.0M/2.27G [00:00<00:25, 89.1MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "tokenizer.json:  61%|█████████████▌        | 10.5M/17.1M [00:00<00:00, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "tokenizer_config.json: 100%|███████████████████| 444/444 [00:00<00:00, 2.33MB/s]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "tokenizer.json: 100%|██████████████████████| 17.1M/17.1M [00:00<00:00, 70.1MB/s]\r\n",
      "\r\n",
      "pytorch_model.bin:   2%|▎                   | 41.9M/2.27G [00:00<00:16, 137MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:   2%|▍                     | 41.9M/2.27G [00:00<00:17, 127MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "tokenizer.json: 100%|██████████████████████| 17.1M/17.1M [00:00<00:00, 97.8MB/s]\r\n",
      "\r\n",
      "pytorch_model.bin:   3%|▌                   | 62.9M/2.27G [00:00<00:14, 156MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:   3%|▌                     | 62.9M/2.27G [00:00<00:15, 143MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "bm25.jpg: 100%|███████████████████████████████| 132k/132k [00:00<00:00, 325kB/s]\r\n",
      "Fetching 30 files:  27%|██████▋                  | 8/30 [00:00<00:01, 15.98it/s]\r\n",
      "pytorch_model.bin:   4%|▋                   | 83.9M/2.27G [00:00<00:13, 166MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:   4%|▉                     | 94.4M/2.27G [00:00<00:11, 183MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:   5%|█                    | 115M/2.27G [00:00<00:11, 187MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:   6%|█▎                     | 126M/2.27G [00:00<00:10, 202MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:   6%|█▎                   | 147M/2.27G [00:00<00:10, 198MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:   7%|█▌                     | 157M/2.27G [00:00<00:09, 215MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:   8%|█▉                     | 189M/2.27G [00:01<00:09, 222MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:   8%|█▋                   | 178M/2.27G [00:00<00:10, 204MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  10%|██▏                    | 220M/2.27G [00:01<00:08, 231MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:   9%|█▉                   | 210M/2.27G [00:01<00:09, 212MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  11%|██▌                    | 252M/2.27G [00:01<00:08, 237MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  11%|██▏                  | 241M/2.27G [00:01<00:09, 209MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  12%|██▊                    | 283M/2.27G [00:01<00:08, 240MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  12%|██▌                  | 273M/2.27G [00:01<00:09, 215MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  14%|███▏                   | 315M/2.27G [00:01<00:08, 239MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  13%|██▊                  | 304M/2.27G [00:01<00:09, 217MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  15%|███▌                   | 346M/2.27G [00:01<00:08, 239MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  15%|███                  | 336M/2.27G [00:01<00:08, 219MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  17%|███▊                   | 377M/2.27G [00:01<00:07, 237MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  16%|███▍                 | 367M/2.27G [00:01<00:08, 222MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  18%|████▏                  | 409M/2.27G [00:01<00:07, 233MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  18%|███▋                 | 398M/2.27G [00:01<00:08, 223MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  19%|████▍                  | 440M/2.27G [00:02<00:07, 242MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  19%|███▉                 | 430M/2.27G [00:02<00:08, 226MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  21%|████▊                  | 472M/2.27G [00:02<00:07, 246MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  20%|████▎                | 461M/2.27G [00:02<00:07, 232MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  22%|█████                  | 503M/2.27G [00:02<00:07, 248MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  22%|████▌                | 493M/2.27G [00:02<00:07, 227MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  24%|█████▍                 | 535M/2.27G [00:02<00:07, 246MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  25%|█████▋                 | 566M/2.27G [00:02<00:06, 250MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  23%|████▊                | 524M/2.27G [00:02<00:07, 225MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  26%|██████                 | 598M/2.27G [00:02<00:06, 249MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  24%|█████▏               | 556M/2.27G [00:02<00:07, 231MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  28%|██████▍                | 629M/2.27G [00:02<00:06, 245MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  26%|█████▍               | 587M/2.27G [00:02<00:07, 229MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  29%|██████▋                | 661M/2.27G [00:02<00:06, 249MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  27%|█████▋               | 619M/2.27G [00:02<00:07, 228MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  31%|███████                | 692M/2.27G [00:03<00:06, 251MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  29%|██████               | 650M/2.27G [00:03<00:07, 227MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  32%|███████▎               | 724M/2.27G [00:03<00:06, 249MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  30%|██████▎              | 682M/2.27G [00:03<00:06, 231MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  33%|███████▋               | 755M/2.27G [00:03<00:06, 249MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  31%|██████▌              | 713M/2.27G [00:03<00:06, 227MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  35%|███████▉               | 786M/2.27G [00:03<00:06, 245MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  33%|██████▉              | 744M/2.27G [00:03<00:06, 220MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  36%|████████▎              | 818M/2.27G [00:03<00:06, 240MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  34%|███████▏             | 776M/2.27G [00:03<00:06, 222MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  37%|████████▌              | 849M/2.27G [00:03<00:05, 245MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  36%|███████▍             | 807M/2.27G [00:03<00:06, 226MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  39%|████████▉              | 881M/2.27G [00:03<00:05, 242MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  37%|███████▊             | 839M/2.27G [00:03<00:06, 230MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  40%|█████████▎             | 912M/2.27G [00:03<00:05, 238MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  38%|████████             | 870M/2.27G [00:04<00:06, 230MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  42%|█████████▌             | 944M/2.27G [00:04<00:05, 240MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  40%|████████▎            | 902M/2.27G [00:04<00:06, 223MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  43%|█████████▉             | 975M/2.27G [00:04<00:05, 234MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  41%|████████▋            | 933M/2.27G [00:04<00:06, 221MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  44%|█████████▊            | 1.01G/2.27G [00:04<00:05, 236MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  46%|██████████            | 1.04G/2.27G [00:04<00:05, 241MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  42%|████████▉            | 965M/2.27G [00:04<00:05, 221MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  47%|██████████▍           | 1.07G/2.27G [00:04<00:05, 239MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  44%|█████████▏           | 996M/2.27G [00:04<00:05, 218MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  49%|██████████▋           | 1.10G/2.27G [00:04<00:04, 238MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  45%|█████████           | 1.03G/2.27G [00:04<00:05, 220MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  50%|██████████▉           | 1.13G/2.27G [00:04<00:04, 238MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  47%|█████████▎          | 1.06G/2.27G [00:04<00:05, 222MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  51%|███████████▎          | 1.16G/2.27G [00:05<00:04, 226MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  48%|█████████▌          | 1.09G/2.27G [00:05<00:05, 211MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  53%|███████████▌          | 1.20G/2.27G [00:05<00:04, 227MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  49%|█████████▉          | 1.12G/2.27G [00:05<00:05, 209MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  54%|███████████▉          | 1.23G/2.27G [00:05<00:04, 235MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  51%|██████████▏         | 1.15G/2.27G [00:05<00:05, 211MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  56%|████████████▏         | 1.26G/2.27G [00:05<00:04, 235MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  52%|██████████▍         | 1.18G/2.27G [00:05<00:05, 215MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  57%|████████████▌         | 1.29G/2.27G [00:05<00:04, 235MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  54%|██████████▋         | 1.22G/2.27G [00:05<00:04, 220MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  58%|████████████▊         | 1.32G/2.27G [00:05<00:04, 236MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  55%|██████████▉         | 1.25G/2.27G [00:05<00:04, 223MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  60%|█████████████▏        | 1.35G/2.27G [00:05<00:03, 237MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  56%|███████████▎        | 1.28G/2.27G [00:05<00:04, 221MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  61%|█████████████▍        | 1.38G/2.27G [00:05<00:03, 239MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  62%|█████████████▋        | 1.42G/2.27G [00:06<00:03, 241MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  58%|███████████▌        | 1.31G/2.27G [00:06<00:04, 217MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  64%|██████████████        | 1.45G/2.27G [00:06<00:03, 237MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  59%|███████████▊        | 1.34G/2.27G [00:06<00:04, 214MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  65%|██████████████▎       | 1.48G/2.27G [00:06<00:03, 233MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  60%|████████████        | 1.37G/2.27G [00:06<00:04, 210MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  67%|██████████████▋       | 1.51G/2.27G [00:06<00:03, 220MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  62%|████████████▎       | 1.41G/2.27G [00:06<00:04, 201MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  68%|██████████████▉       | 1.54G/2.27G [00:06<00:03, 223MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  63%|████████████▌       | 1.43G/2.27G [00:06<00:04, 201MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  64%|████████████▋       | 1.45G/2.27G [00:06<00:04, 202MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  69%|███████████████▎      | 1.57G/2.27G [00:06<00:03, 221MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  65%|████████████▉       | 1.47G/2.27G [00:06<00:04, 199MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  71%|███████████████▌      | 1.60G/2.27G [00:06<00:03, 219MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  66%|█████████████       | 1.49G/2.27G [00:06<00:03, 198MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  72%|███████████████▉      | 1.64G/2.27G [00:07<00:02, 221MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  66%|█████████████▎      | 1.51G/2.27G [00:07<00:03, 198MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  74%|████████████████▏     | 1.67G/2.27G [00:07<00:02, 222MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  68%|█████████████▌      | 1.54G/2.27G [00:07<00:03, 203MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  69%|█████████████▊      | 1.56G/2.27G [00:07<00:03, 203MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  75%|████████████████▍     | 1.70G/2.27G [00:07<00:02, 221MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  70%|█████████████▉      | 1.58G/2.27G [00:07<00:03, 199MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  76%|████████████████▊     | 1.73G/2.27G [00:07<00:02, 208MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  71%|██████████████▏     | 1.60G/2.27G [00:07<00:03, 185MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  78%|█████████████████     | 1.76G/2.27G [00:07<00:02, 213MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  72%|██████████████▎     | 1.63G/2.27G [00:07<00:03, 187MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  72%|██████████████▍     | 1.65G/2.27G [00:07<00:03, 189MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  79%|█████████████████▍    | 1.79G/2.27G [00:07<00:02, 213MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  73%|██████████████▋     | 1.67G/2.27G [00:07<00:03, 193MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  80%|█████████████████▋    | 1.82G/2.27G [00:08<00:02, 211MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  74%|██████████████▊     | 1.69G/2.27G [00:08<00:03, 193MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  75%|███████████████     | 1.71G/2.27G [00:08<00:02, 195MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  82%|██████████████████    | 1.86G/2.27G [00:08<00:01, 208MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  76%|███████████████▏    | 1.73G/2.27G [00:08<00:02, 187MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  83%|██████████████████▎   | 1.89G/2.27G [00:08<00:01, 214MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  77%|███████████████▍    | 1.75G/2.27G [00:08<00:02, 179MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  85%|██████████████████▌   | 1.92G/2.27G [00:08<00:01, 216MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  78%|███████████████▋    | 1.78G/2.27G [00:08<00:02, 186MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  86%|██████████████████▉   | 1.95G/2.27G [00:08<00:01, 215MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  79%|███████████████▉    | 1.80G/2.27G [00:08<00:02, 185MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  87%|███████████████████▏  | 1.98G/2.27G [00:08<00:01, 215MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  80%|████████████████    | 1.82G/2.27G [00:08<00:02, 185MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  89%|███████████████████▌  | 2.01G/2.27G [00:08<00:01, 212MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  81%|████████████████▎   | 1.85G/2.27G [00:08<00:02, 188MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  82%|████████████████▍   | 1.87G/2.27G [00:08<00:02, 190MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  90%|███████████████████▊  | 2.04G/2.27G [00:09<00:01, 213MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  83%|████████████████▌   | 1.89G/2.27G [00:09<00:02, 188MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  92%|████████████████████▏ | 2.08G/2.27G [00:09<00:00, 218MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  84%|████████████████▊   | 1.91G/2.27G [00:09<00:01, 191MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  93%|████████████████████▍ | 2.11G/2.27G [00:09<00:00, 217MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  85%|████████████████▉   | 1.93G/2.27G [00:09<00:01, 192MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  86%|█████████████████▏  | 1.95G/2.27G [00:09<00:01, 193MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  94%|████████████████████▊ | 2.14G/2.27G [00:09<00:00, 214MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  87%|█████████████████▎  | 1.97G/2.27G [00:09<00:01, 194MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  96%|█████████████████████ | 2.17G/2.27G [00:09<00:00, 214MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  88%|█████████████████▌  | 1.99G/2.27G [00:09<00:01, 188MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  97%|█████████████████████▎| 2.20G/2.27G [00:09<00:00, 219MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  89%|█████████████████▊  | 2.02G/2.27G [00:09<00:01, 199MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data:  99%|█████████████████████▋| 2.23G/2.27G [00:09<00:00, 222MB/s]\u001b[A\u001b[A\r\n",
      "pytorch_model.bin:  90%|██████████████████  | 2.04G/2.27G [00:09<00:01, 200MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  91%|██████████████████▏ | 2.07G/2.27G [00:09<00:01, 203MB/s]\u001b[A\r\n",
      "\r\n",
      "model.onnx_data: 100%|██████████████████████| 2.27G/2.27G [00:10<00:00, 226MB/s]\r\n",
      "Fetching 30 files:  63%|███████████████▏        | 19/30 [00:10<00:06,  1.68it/s]\r\n",
      "pytorch_model.bin:  92%|██████████████████▍ | 2.09G/2.27G [00:10<00:00, 204MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  93%|██████████████████▋ | 2.12G/2.27G [00:10<00:00, 213MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  95%|██████████████████▉ | 2.15G/2.27G [00:10<00:00, 214MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  96%|███████████████████▏| 2.18G/2.27G [00:10<00:00, 216MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  97%|███████████████████▍| 2.21G/2.27G [00:10<00:00, 218MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  99%|███████████████████▊| 2.24G/2.27G [00:10<00:00, 225MB/s]\u001b[A\r\n",
      "pytorch_model.bin: 100%|████████████████████| 2.27G/2.27G [00:10<00:00, 209MB/s]\r\n",
      "Fetching 30 files: 100%|████████████████████████| 30/30 [00:11<00:00,  2.67it/s]\r\n",
      "Fetching 30 files: 100%|████████████████████████| 30/30 [00:10<00:00,  2.74it/s]\r\n",
      "Generating train split: 3229 examples [00:01, 2769.60 examples/s]\r\n",
      "/kaggle/working/FlagEmbedding/FlagEmbedding/finetune/embedder/encoder_only/m3/runner.py:161: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `EncoderOnlyEmbedderM3Trainer.__init__`. Use `processing_class` instead.\r\n",
      "  trainer = EncoderOnlyEmbedderM3Trainer(\r\n",
      "/kaggle/working/FlagEmbedding/FlagEmbedding/finetune/embedder/encoder_only/m3/runner.py:161: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `EncoderOnlyEmbedderM3Trainer.__init__`. Use `processing_class` instead.\r\n",
      "  trainer = EncoderOnlyEmbedderM3Trainer(\r\n",
      "Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\r\n",
      "Creating extension directory /root/.cache/torch_extensions/py311_cu124/fused_adam...\r\n",
      "Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\r\n",
      "Detected CUDA files, patching ldflags\r\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu124/fused_adam/build.ninja...\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \r\n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\r\n",
      "  warnings.warn(\r\n",
      "Building extension module fused_adam...\r\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\n",
      "[1/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output multi_tensor_adam.cuda.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.11/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/lib/python3.11/dist-packages/deepspeed/ops/csrc/adam -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_75,code=compute_75 -std=c++17 -c /usr/local/lib/python3.11/dist-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o \r\n",
      "[2/3] c++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.11/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/lib/python3.11/dist-packages/deepspeed/ops/csrc/adam -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -c /usr/local/lib/python3.11/dist-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o \r\n",
      "[3/3] c++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/usr/local/lib/python3.11/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_adam.so\r\n",
      "Loading extension module fused_adam...\r\n",
      "Time to load fused_adam op: 38.86413884162903 seconds\r\n",
      "Loading extension module fused_adam...\r\n",
      "Time to load fused_adam op: 38.872573375701904 seconds\r\n",
      "[2025-06-10 14:00:00,211] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started\r\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\r\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\r\n",
      "  warnings.warn(\r\n",
      "[2025-06-10 14:00:02,145] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m23122004\u001b[0m (\u001b[33m23122004-hcmus\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/FlagEmbedding/wandb/run-20250610_140002-d711b4gv\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/kaggle/working/my_finetuned_bge_m3_legal\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/23122004-hcmus/huggingface\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/23122004-hcmus/huggingface/runs/d711b4gv\u001b[0m\r\n",
      "  0%|                                                   | 0/603 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\r\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.5709, 'grad_norm': 17.005016326904297, 'learning_rate': 1.4574673767843407e-05, 'epoch': 0.1}\r\n",
      "{'loss': 0.2248, 'grad_norm': 8.19748592376709, 'learning_rate': 1.794693574163343e-05, 'epoch': 0.2}\r\n",
      "{'loss': 0.129, 'grad_norm': 9.39587688446045, 'learning_rate': 1.9919582538908503e-05, 'epoch': 0.3}\r\n",
      "{'loss': 0.1106, 'grad_norm': 9.270289421081543, 'learning_rate': 1.9335793357933582e-05, 'epoch': 0.4}\r\n",
      "{'loss': 0.1069, 'grad_norm': 4.786922454833984, 'learning_rate': 1.859778597785978e-05, 'epoch': 0.5}\r\n",
      "{'loss': 0.1012, 'grad_norm': 1.145559549331665, 'learning_rate': 1.785977859778598e-05, 'epoch': 0.59}\r\n",
      "{'loss': 0.1382, 'grad_norm': 6.310090065002441, 'learning_rate': 1.7121771217712177e-05, 'epoch': 0.69}\r\n",
      "{'loss': 0.1251, 'grad_norm': 2.325376033782959, 'learning_rate': 1.638376383763838e-05, 'epoch': 0.79}\r\n",
      "{'loss': 0.0996, 'grad_norm': 3.734118700027466, 'learning_rate': 1.5645756457564577e-05, 'epoch': 0.89}\r\n",
      "{'loss': 0.1056, 'grad_norm': 4.396273612976074, 'learning_rate': 1.4907749077490776e-05, 'epoch': 0.99}\r\n",
      "{'loss': 0.0965, 'grad_norm': 1.8005900382995605, 'learning_rate': 1.4169741697416974e-05, 'epoch': 1.09}\r\n",
      "{'loss': 0.0838, 'grad_norm': 1.1088021993637085, 'learning_rate': 1.3431734317343174e-05, 'epoch': 1.19}\r\n",
      "{'loss': 0.0732, 'grad_norm': 1.6699388027191162, 'learning_rate': 1.2693726937269372e-05, 'epoch': 1.29}\r\n",
      "{'loss': 0.0888, 'grad_norm': 1.1648662090301514, 'learning_rate': 1.1955719557195573e-05, 'epoch': 1.39}\r\n",
      "{'loss': 0.0664, 'grad_norm': 2.6270930767059326, 'learning_rate': 1.1217712177121771e-05, 'epoch': 1.49}\r\n",
      "{'loss': 0.1059, 'grad_norm': 4.503040790557861, 'learning_rate': 1.0479704797047971e-05, 'epoch': 1.59}\r\n",
      "{'loss': 0.0764, 'grad_norm': 12.14943790435791, 'learning_rate': 9.741697416974171e-06, 'epoch': 1.69}\r\n",
      "{'loss': 0.0704, 'grad_norm': 1.0967463254928589, 'learning_rate': 9.00369003690037e-06, 'epoch': 1.79}\r\n",
      "{'loss': 0.0768, 'grad_norm': 5.3354387283325195, 'learning_rate': 8.26568265682657e-06, 'epoch': 1.89}\r\n",
      "{'loss': 0.0821, 'grad_norm': 4.471188545227051, 'learning_rate': 7.527675276752768e-06, 'epoch': 1.99}\r\n",
      "{'loss': 0.078, 'grad_norm': 6.055809020996094, 'learning_rate': 6.752767527675277e-06, 'epoch': 2.09}\r\n",
      "{'loss': 0.0546, 'grad_norm': 0.33503010869026184, 'learning_rate': 6.014760147601476e-06, 'epoch': 2.19}\r\n",
      "{'loss': 0.087, 'grad_norm': 15.65578556060791, 'learning_rate': 5.276752767527676e-06, 'epoch': 2.29}\r\n",
      "{'loss': 0.0738, 'grad_norm': 0.752457857131958, 'learning_rate': 4.538745387453875e-06, 'epoch': 2.39}\r\n",
      "{'loss': 0.0793, 'grad_norm': 6.49639368057251, 'learning_rate': 3.800738007380074e-06, 'epoch': 2.49}\r\n",
      " 83%|████████████████████████████████▎      | 500/603 [4:47:37<59:58, 34.94s/it]Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\r\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\r\n",
      "{'loss': 0.0725, 'grad_norm': 0.9497502446174622, 'learning_rate': 3.0627306273062733e-06, 'epoch': 2.58}\r\n",
      "{'loss': 0.0762, 'grad_norm': 3.6575143337249756, 'learning_rate': 2.3247232472324725e-06, 'epoch': 2.68}\r\n",
      "{'loss': 0.0584, 'grad_norm': 1.6257380247116089, 'learning_rate': 1.5867158671586716e-06, 'epoch': 2.78}\r\n",
      "{'loss': 0.0903, 'grad_norm': 5.231808185577393, 'learning_rate': 8.487084870848709e-07, 'epoch': 2.88}\r\n",
      "{'loss': 0.0502, 'grad_norm': 0.8594300150871277, 'learning_rate': 1.1070110701107011e-07, 'epoch': 2.98}\r\n",
      "100%|███████████████████████████████████████| 603/603 [5:47:45<00:00, 34.61s/it]Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\r\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\r\n",
      "{'train_runtime': 20895.8907, 'train_samples_per_second': 0.463, 'train_steps_per_second': 0.029, 'train_loss': 0.10814213006452937, 'epoch': 3.0}\r\n",
      "100%|███████████████████████████████████████| 603/603 [5:48:14<00:00, 34.65s/it]\r\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\r\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\r\n",
      "\u001b[1;34mwandb\u001b[0m: \r\n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33m/kaggle/working/my_finetuned_bge_m3_legal\u001b[0m at: \u001b[34mhttps://wandb.ai/23122004-hcmus/huggingface/runs/d711b4gv\u001b[0m\r\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250610_140002-d711b4gv/logs\u001b[0m\r\n",
      "[rank0]:[W610 19:48:25.894954434 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\r\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node 2 \\\n",
    "    -m FlagEmbedding.finetune.embedder.encoder_only.m3 \\\n",
    "    --model_name_or_path BAAI/bge-m3  \\\n",
    "    --cache_dir /kaggle/working/cache/model \\\n",
    "    --train_data /kaggle/working/training_data_for_flagembedding.jsonl \\\n",
    "    --cache_path /kaggle/working/cache/data \\\n",
    "    --train_group_size 2 \\\n",
    "    --query_max_len 128 \\\n",
    "    --passage_max_len 1000 \\\n",
    "    --pad_to_multiple_of 8 \\\n",
    "    --same_dataset_within_batch True \\\n",
    "    --small_threshold 0 \\\n",
    "    --drop_threshold 0 \\\n",
    "    --output_dir /kaggle/working/my_finetuned_bge_m3_legal \\\n",
    "    --overwrite_output_dir \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --bf16 \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --dataloader_drop_last True \\\n",
    "    --warmup_ratio 0.1 \\\n",
    "    --gradient_checkpointing \\\n",
    "    --deepspeed /kaggle/working/FlagEmbedding/examples/finetune/ds_stage0.json \\\n",
    "    --logging_steps 20 \\\n",
    "    --weight_decay 0.01 \\\n",
    "    --negatives_cross_device \\\n",
    "    --temperature 0.02 \\\n",
    "    --normalize_embeddings True \\\n",
    "    --unified_finetuning True \\\n",
    "    --use_self_distill True \\\n",
    "    --fix_encoder False \\\n",
    "    --self_distill_start_step 0 \\\n",
    "    --gradient_accumulation_steps 8"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7620494,
     "sourceId": 12104463,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21200.327541,
   "end_time": "2025-06-10T19:48:29.449052",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-10T13:55:09.121511",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
